<html lang=en><meta charset=UTF-8><title>Hayden Housen - Resume</title><style>@import url('https://fonts.googleapis.com/css2?family=Barlow:wght@100;200;300;400;500;600;700;800;900&display=swap');
body{color:#000;background:#eee;margin:40px 0;font-family:Barlow,sans-serif;font-size:12.5px;font-weight:400;line-height:1.1}#resume{margin:0 auto;max-width:8.5in;padding:40px 47px;background:#fff;border:1px solid #CCCCCC;box-shadow:2px 2px 4px #AAAAAA;-webkit-box-shadow:2px 2px 4px #AAAAAA;box-sizing:border-box;position:relative}h1{margin:0 0 8px;font-weight:600;font-size:36px}h2{margin:11px 0 7px;font-weight:600;color:#a82029;font-size:20px;display:flex}h2:after {margin:11px 0 0 16px;display:inline-block;flex-grow:1;height:2px;background-color:#a82029;content:""}h2:first-child {margin:0!important}h2 + h3{margin:0 0 .3em 0}h3{font-size:100%;margin:8px 0 .3em 0;display:flex;align-items:baseline}h3 > span:first-child {margin:0;font-weight:600;color:#000;font-size:17px;width:260px}h3 > span:last-child {display:flex;justify-content:space-between;align-items:baseline;flex-grow:1}h3 > span span{font-size:13px;font-weight:600}h3 > span span:last-child {color:#4f5157}h2 ~ p span:first-child {display:inline-block;width:260px;font-weight:600}strong{font-weight:600}p{margin:0 0 .5em 0;padding:0}ul{padding:0;margin:0 0 0 1.5em}h1 + ul{text-align:left;margin:0;padding:0}h1 + ul > li{display:inline;white-space:pre;list-style-type:none}h1 + ul > li:after {content:"\2022";padding:0 5px}h1 + ul > li:last-child:after {content:""}h1 + ul + p{margin:1em 0}h3 + ul li{margin-bottom:5px}h1 ~ ul:nth-child(3){position:absolute;padding:inherit;top:0;right:0;margin:0;text-align:right;list-style:none}p:last-child {margin-bottom:0}@media print{body{margin:0;padding:0;background:none}#resume{margin:0;padding:0;border:0;background:none;box-shadow:none;-webkit-box-shadow:none}abbr{text-decoration:none;font-variant:none}a,a:hover ,a:link,a:visited{color:#000;text-decoration:underline}}@page {size:letter;margin:40px 47px}@media screen and (max-width: 800px){body{font-size:16pt;margin:0;padding:0;background:#fff!important}#resume{margin:0;padding:1em;border:0;background:none;box-shadow:none;-webkit-box-shadow:none}}</style><body><div id=resume><h1>Hayden Housen</h1><ul><li><a href=mailto:hayden@haydenhousen.com>hayden@haydenhousen.com</a><li>(845) 518-1380<li>Ithaca, NY</ul><ul><li><a href=https://haydenhousen.com>haydenhousen.com</a><li><a href=https://github.com/HHousen>github.com/HHousen</a><li><a href=https://linkedin.com/in/HHousen>linkedin.com/in/HHousen</a></ul><h2>Education</h2><h3><span>Cornell University</span> <span><span>Computer Science, BS</span> <span>Aug 2021 – May 2025</span></span></h3><ul><li>GPA: 3.865, Dean’s Honor List, Rawlings Presidential Research Scholar, Cybersecurity Club President<li>Coursework: Machine Learning, Artificial Intelligence, Functional Programming, Linear Algebra, Probability and Statistics</ul><h2>Work Experience</h2><h3><span>Software Engineering Intern</span> <span><span><a href=https://vocode.dev>Vocode</a> (YC W23)</span> <span>May 2023 – Aug 2023</span></span></h3><ul><li>Collaborated directly with founders as a pivotal engineer to shape Vocode’s pioneering AI-driven call automation solutions.<li>Demonstrated versatility as a fullstack developer by building the FastAPI backend, open-source self-hosted service (Python and asyncio), and frontend dashboard (Next.js), while also resolving issues and reviewing pull requests from the community.<li>Evaluated the latencies of multiple LLMs, speech-to-text APIs, and synthesis services to enhance Vocode’s performance.</ul><h3><span>Undergraduate Researcher</span> <span><span>Cornell University</span> <span>Sept 2021 – Present</span></span></h3><ul><li>Worked with Dr. Kevin Ellis on unsupervised object discovery using Slot Attention and investigated applications to options learning.<li>Overcame bias in paraphrase identification by using transformers & out-of-distribution detection techniques: “<a href=https://haydenhousen.com/media/GAPX.pdf>GAPX: Generalized</a> <a href=https://haydenhousen.com/media/GAPX.pdf>Autoregressive Paraphrase-Identification X</a>.” Published in <strong>NeurIPS 2022</strong> (3rd author). Advised by Dr. Sernam Lim at Meta AI.</ul><h3><span>Machine Learning Intern</span> <span><span><a href=https://ada.cx>Ada Support</a> (Remote)</span> <span>May 2022 – Aug 2022</span></span></h3><ul><li><strong>Improved Ada’s production accuracy by 8%</strong> using only 3% of production data by developing a novel intent classification pipeline.<li>Conducted <strong>>60 experiments</strong> and trained >110 models to determine the most accurate methodology.<li>Experimented with knowledge transfer, unsupervised learning of sentence embeddings, multi-task learning, and contrastive losses in the context of transformers and support vector machines.</ul><h3><span>Machine Learning Intern</span> <span><span><a href=https://ada.cx>Ada Support</a> (Remote)</span> <span>May 2021 – Aug 2021</span></span></h3><ul><li>Led the discovery and experimentation phases of a project to enable Ada chatbots to better understand non-English languages.<li>Wrote a data processing pipeline to efficiently clean and analyze <strong>9 billion</strong> chat messages for machine learning models.<li>Researched novel techniques in multilingual intent prediction and cultivated skills in PyTorch, transformers, and pandas.</ul><h2>Projects</h2><h3><span>AI Music Workstation</span> <span><span><a href=https://sonauto.app>Sonauto</a></span> <span>Jan 2023 – Present</span></span></h3><ul><li>Training diffusion models to generate long-form pop songs through a collaboration with StabilityAI researchers.<li>Developing a diffusion autoencoder using PyTorch, achieving 64x music compression to a continuous latent space, by testing various diffusion objectives, loss functions, and attention mechanisms.<li>Creating <a href=https://sonauto.app>an app</a> with React Native and Firebase to streamline hit pop song creation using generative AI.</ul><h3><span>AI Lecture Notes Generation</span> <span><span><a href=https://haydenhousen.com/projects/lecture2notes/>lecture2notes</a></span> <span>Sept 2019 – Jan 2022</span></span></h3><ul><li>Created a state-of-the-art system to summarize classroom lectures using PyTorch, transformers (BERT), optical character recognition, speech to text, and convolutional neural networks. Source on <a href=https://github.com/HHousen/lecture2notes/>GitHub</a>. Learn more in the <a href=https://haydenhousen.com/media/lecture2notes-paper-v1.pdf>research paper</a>.<li>Named a <strong>top 300 scholar in the 2021 Regeneron Science Talent Search</strong>, the nation’s oldest and most prestigious science and math competition for high school seniors.<li>Deployed ML pipeline in production via a <a href=https://lecture2notes.com/>full-stack website</a> powered by Docker, Flask, Celery, Bootstrap, and Stripe.</ul><h3><span>Neural Summarization Library</span> <span><span><a href=https://github.com/HHousen/TransformerSum>TransformerSum</a></span> <span>Mar 2020 – Oct 2020</span></span></h3><ul><li>Furthered research in neural-network text summarization with a focus on long document summarization. <strong>340+ stars on <a href=https://github.com/HHousen/TransformerSum>GitHub</a></strong>.<li>4.45x smaller than the state-of-the-art model but 94% as accurate at release. 10+ pre-trained models available.<li>Rewrote researchers’ code with enhanced performance and a focus on code readability and <a href=https://transformersum.readthedocs.io/en/latest/>thorough documentation</a>.</ul><h2>Technologies and Languages</h2><p><span>Languages</span> <span>Python, Java, JavaScript, HTML/CSS, SQL, OCaml, C, Bash</span><p><span>Machine Learning</span> <span>PyTorch, transformers (BERT), scikit-learn, NumPy, Lightning, pandas, OpenCV, Spacy</span><p><span>Web</span> <span>Flask, FastAPI, React Native (Expo), Bootstrap, jQuery, web scraping, API design</span><p><span>DB and DevOps</span> <span>MongoDB, PostgreSQL, MySQL, Docker, AWS, Firebase, Supabase, CI/CD, Git</span></div>