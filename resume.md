<!-- The (first) h1 will be used as the <title> of the HTML page -->
# Hayden Housen

<!-- The unordered list immediately after the h1 will be formatted on a single
line. It is intended to be used for contact details -->
- <hayden@haydenhousen.com>
- (845) 518-1380
- Ithaca, NY

<!-- Social Links -->
- [haydenhousen.com](https://haydenhousen.com)
- [github.com/HHousen](https://github.com/HHousen)
- [linkedin.com/in/HHousen](https://linkedin.com/in/HHousen)

<!-- The paragraph after the h1 and ul and before the first h2 is optional. It
is intended to be used for a short summary. -->

## Education

### <span>Cornell University</span> <span><span>Computer Science, BS</span> <span>Aug 2021 -- May 2025</span></span>

- GPA: 3.865, Dean's Honor List, Rawlings Presidential Research Scholar
- Coursework: Machine Learning, Artificial Intelligence, Functional Programming, Linear Algebra, Probability and Statistics

## Work Experience

<!-- You have to wrap the "left" and "right" half of these headings in spans by
hand -->
### <span>Undergraduate Researcher</span> <span><span>Cornell University</span> <span>Sept 2021 -- Present</span></span>

- Currently working with Dr. Kevin Ellis on unsupervised object discovery using Slot Attention.
- Overcame bias in paraphrase identification by using transformers & out-of-distribution detection techniques: "[GAPX: Generalized](https://haydenhousen.com/media/GAPX.pdf) [Autoregressive Paraphrase-Identification X](https://haydenhousen.com/media/GAPX.pdf)." Published in **NeurIPS 2022** (3rd author). Advised by Dr. Sernam Lim at Meta AI.

### <span>Machine Learning Intern</span> <span><span><a href="https://ada.cx">Ada Support</a> (Remote)</span> <span>May 2022 -- Aug 2022</span></span>

- **Improved Ada's production accuracy by 8%** using only 3% of production data by developing a novel intent classification pipeline.
- Conducted **>60 experiments** and trained >110 models to determine the most accurate methodology.
- Experimented with knowledge transfer, unsupervised learning of sentence embeddings, multi-task learning, and contrastive losses in the context of transformers and support vector machines.

### <span>Machine Learning Intern</span> <span><span><a href="https://ada.cx">Ada Support</a> (Remote)</span> <span>May 2021 -- Aug 2021</span></span>

- Led the discovery and experimentation phases of a project to enable Ada chatbots to better understand non-English languages.
- Wrote a data processing pipeline to efficiently clean and analyze **9 billion** chat messages for machine learning models.
- Researched novel techniques in multilingual intent prediction and cultivated skills in PyTorch, transformers, and pandas.

## Projects

### <span>AI Lecture Notes Generation</span> <span><span><a href="https://haydenhousen.com/projects/lecture2notes/">lecture2notes</a></span> <span>Sept 2019 -- Jan 2022</span></span>

- Created a state-of-the-art system to summarize classroom lectures using PyTorch, transformers (BERT), optical character recognition, speech to text, and convolutional neural networks. Source on [GitHub](https://github.com/HHousen/lecture2notes/). Learn more in the [research paper](https://haydenhousen.com/media/lecture2notes-paper-v1.pdf).
- Named a **top 300 scholar in the 2021 Regeneron Science Talent Search**, the nationâ€™s oldest and most prestigious science and math competition for high school seniors.
- Deployed ML pipeline in production via a [full-stack website](https://lecture2notes.com/) powered by Docker, Flask, Celery, Bootstrap, and Stripe.

### <span>Neural Summarization Library</span> <span><span><a href="https://github.com/HHousen/TransformerSum">TransformerSum</a></span> <span>Mar 2020 -- Oct 2020</span></span>

- Furthered research in neural-network text summarization with a focus on long document summarization. **340+ stars on [GitHub](https://github.com/HHousen/TransformerSum)**.
- 4.45x smaller than the state-of-the-art model but 94% as accurate at release. 10+ pre-trained models available.
- Rewrote researchers' code with enhanced performance and a focus on code readability and [thorough documentation](https://transformersum.readthedocs.io/en/latest/).

### <span>AI Snow Day Prediction</span> <span><span><a href="https://haydenhousen.com/projects/will-i-have-a-snow-day/">Will I Have A Snow Day.com</a></span> <span>Dec 2019 -- Sept 2020</span></span>

- Created an AI-powered automatic snow day predictor website that improves itself over time using user feedback. Powered by XGBoost, scikit-learn, Materialize.css, SendGrid, and Flask. Source on [GitHub](https://github.com/HHousen/willihaveasnowday).
- Scraped school closings and processed **100GB+** of weather data from NOAA to build a snow day dataset.
- Trained a gradient boosting classifier after extensive data exploration and feature engineering.

### <span>Cybersecurity Challenges</span> <span><span>Capture The Flag</span> <span>Sept 2019 -- Current</span></span>

- Placed in **top 3%** on average in the PicoCTF [2019](https://github.com/HHousen/PicoCTF-2019)/[2021](https://github.com/HHousen/PicoCTF-2021)/[2022](https://github.com/HHousen/PicoCTF-2022) competitions. Learned ethical hacking skills including web exploitation, cryptography, reverse engineering, and binary exploitation. Worked with popular tools included in Kali Linux.
- Wrote technical guides with **over 94,000 views** to document my learning and help others.
- Continuously practicing cybersecurity principles by solving HackTheBox.com machines and [publishing writeups](https://htb.haydenhousen.com/).

## Technologies and Languages

<span>Languages</span> <span>Python, Java, JavaScript, HTML/CSS, SQL, OCaml, C, Bash</span>

<span>Machine Learning</span> <span>PyTorch, transformers (BERT), scikit-learn, NumPy, Lightning, pandas, OpenCV, Spacy</span>

<span>Web</span> <span>Flask, React Native (Expo), Bootstrap, jQuery, web scraping, API design</span>

<span>DB and DevOps</span> <span>MongoDB, PostgreSQL, MySQL, Docker, AWS, Firebase, CI/CD, Git</span>

<!-- Resume [generated from markdown](https://github.com/HHousen/resume) and styled with my custom CSS via a python script. -->
